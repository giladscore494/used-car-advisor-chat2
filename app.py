
import os
import re
import json
import requests
import datetime
import streamlit as st
import pandas as pd
import unidecode
from openai import OpenAI

# =============================
# ××¤×ª×—×•×ª API
# =============================
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")

if not OPENAI_API_KEY or not GEMINI_API_KEY:
    st.error("âŒ ×œ× × ××¦××• ××¤×ª×—×•×ª API. ×•×“× ×©×”×’×“×¨×ª ××•×ª× ×‘-secrets.")
    st.stop()

client = OpenAI(api_key=OPENAI_API_KEY)

# =============================
# ×§×¨×™××” ×‘×˜×•×—×” ×œ-Gemini
# =============================
def safe_gemini_call(payload, model="gemini-2.0-flash"):
    url = f"https://generativelanguage.googleapis.com/v1/models/{model}:generateContent"
    headers = {"Content-Type": "application/json"}
    params = {"key": GEMINI_API_KEY}
    try:
        r = requests.post(url, headers=headers, params=params, json=payload, timeout=90)
        data = r.json()
        if "candidates" not in data:
            return f"×©×’×™××ª Gemini: {data}"
        return data["candidates"][0]["content"]["parts"][0]["text"]
    except Exception as e:
        return f"×©×’×™××”: {e}"

# =============================
# ×§×¨×™××” ×‘×˜×•×—×” ×œ-JSON
# =============================
def parse_gemini_json(answer):
    cleaned = answer.strip()
    if cleaned.startswith("```"):
        cleaned = re.sub(r"```[a-zA-Z]*", "", cleaned)
        cleaned = cleaned.replace("```", "").strip()
    try:
        return json.loads(cleaned)
    except Exception as e:
        return {"error": str(e), "raw": cleaned}

# =============================
# ×©×œ×‘ 1 â€“ Gemini ××¦×™×¢ ×¨×©×™××ª ×“×’××™×
# =============================
def fetch_candidate_models(answers):
    payload = {
        "contents": [{
            "role": "user",
            "parts": [{
                "text": f"""
                ×”××©×ª××© × ×ª×Ÿ ××ª ×”×”×¢×“×¤×•×ª ×”×‘××•×ª:
                {answers}

                ×”×—×–×¨ ×¨×©×™××” ×©×œ ×œ×¤×—×•×ª 10 ×“×’××™× ××ª××™××™×
                ×‘×¤×•×¨××˜ JSON ×¤×©×•×˜:
                ["Model1", "Model2", "Model3", ...]
                ××œ ×ª×•×¡×™×£ ×˜×§×¡×˜ × ×•×¡×£ ××¢×‘×¨ ×œ-JSON.
                """
            }]
        }]
    }
    answer = safe_gemini_call(payload)
    return parse_gemini_json(answer)

# =============================
# ×©×œ×‘ 2 â€“ ×¡×™× ×•×Ÿ ××•×œ ××©×¨×“ ×”×ª×—×‘×•×¨×”
# =============================
def normalize_name(name: str) -> str:
    return unidecode.unidecode(str(name)).lower().replace(" ", "").replace("-", "")

def filter_models_by_registry(candidate_models, answers, df_cars):
    valid_models = []
    df_cars["model_norm"] = df_cars["model"].astype(str).apply(normalize_name)

    for model_name in candidate_models:
        norm = normalize_name(model_name)
        exists = df_cars[df_cars["model_norm"].str.contains(norm, na=False)]
        if exists.empty:
            continue

        # ×’×™×¨
        if answers.get("gearbox") == "××•×˜×•××˜":
            if exists["automatic"].max() != 1:
                continue

        # ×“×œ×§
        if answers.get("engine") and answers["engine"] != "×œ× ××©× ×”":
            fuels = exists["fuel"].unique().tolist()
            if not any(answers["engine"] in f for f in fuels):
                continue

        # ×©× ×ª ×™×™×¦×•×¨
        if answers.get("year_range"):
            year_range = answers["year_range"].replace("+", "").split("â€“")
            year_min, year_max = [int(y) for y in year_range]
            years = exists["year"].astype(int)
            if not any((years >= year_min) & (years <= year_max)):
                continue

        valid_models.append(model_name)

    return valid_models

# =============================
# ×©×œ×‘ 3 â€“ Gemini ××—×–×™×¨ × ×ª×•× ×™× ×™×‘×©×™×
# =============================
def fetch_models_data_with_gemini(valid_models, answers):
    payload = {
        "contents": [{
            "role": "user",
            "parts": [{
                "text": f"""
                ×”××©×ª××© × ×ª×Ÿ ××ª ×”×”×¢×“×¤×•×ª ×”×‘××•×ª:
                {answers}

                ××œ×• ×”×“×’××™× ×©× ×‘×—×¨×• ××—×¨×™ ×¡×™× ×•×Ÿ ××•×œ ××©×¨×“ ×”×ª×—×‘×•×¨×”:
                {valid_models}

                ×”×—×–×¨ × ×ª×•× ×™× ×™×‘×©×™× ×¢×‘×•×¨ ×›×œ ×“×’× ×‘×¤×•×¨××˜ JSON:
                {{
                  "Model Name": {{
                     "price_range": "×˜×•×•×— ××—×™×¨×•×Ÿ ×‘×™×“ ×©× ×™×™×” (â‚ª)",
                     "availability": "×–××™× ×•×ª ×‘×™×©×¨××œ",
                     "insurance_total": "×¢×œ×•×ª ×‘×™×˜×•×— ×—×•×‘×” + ×¦×“ ×’' (â‚ª, ×˜×•×•×— ×¢× ×“×™×¡×§×œ×™×™××¨)",
                     "license_fee": "××’×¨×ª ×¨×™×©×•×™/×˜×¡×˜ ×©× ×ª×™×ª (â‚ª)",
                     "maintenance": "×ª×—×–×•×§×” ×©× ×ª×™×ª ×××•×¦×¢×ª (â‚ª)",
                     "common_issues": "×ª×§×œ×•×ª × ×¤×•×¦×•×ª",
                     "fuel_consumption": "×¦×¨×™×›×ª ×“×œ×§ ×××™×ª×™×ª (×§×´× ×œ×œ×™×˜×¨)",
                     "depreciation": "×™×¨×™×“×ª ×¢×¨×š ×××•×¦×¢×ª (%)",
                     "safety": "×“×™×¨×•×’ ×‘×˜×™×—×•×ª (×›×•×›×‘×™×)",
                     "parts_availability": "×–××™× ×•×ª ×—×œ×¤×™× ×‘×™×©×¨××œ"
                  }}
                }}
                ××œ ×ª×•×¡×™×£ ×˜×§×¡×˜ × ×•×¡×£ ××¢×‘×¨ ×œ-JSON.
                """
            }]
        }]
    }
    answer = safe_gemini_call(payload)
    return parse_gemini_json(answer)

# =============================
# ×©×œ×‘ 4 â€“ GPT ××¡×›× ×•××“×¨×’
# =============================
def final_recommendation_with_gpt(answers, models_data):
    text = f"""
    ×ª×©×•×‘×•×ª ×”××©×ª××©:
    {answers}

    × ×ª×•× ×™ ×”×“×’××™×:
    {models_data}

    ×¦×•×¨ ×¡×™×›×•× ×‘×¢×‘×¨×™×ª:
    - ×‘×—×¨ ××ª 5 ×”×“×’××™× ×”×˜×•×‘×™× ×‘×™×•×ª×¨ ×‘×œ×‘×“
    - ×”×¡×‘×¨ ×™×ª×¨×•× ×•×ª ×•×—×¡×¨×•× ×•×ª ×©×œ ×›×œ ××—×“
    - ×”×ª×™×™×—×¡ ×‘××™×•×—×“ ×œ×¢×œ×•×ª ×‘×™×˜×•×—, ×ª×—×–×•×§×”, ×™×¨×™×“×ª ×¢×¨×š ×•×¦×¨×™×›×ª ×“×œ×§
    - ×”×¦×’ ××ª ×”×¡×™×‘×•×ª ×œ××” ×”× ×”×›×™ ××ª××™××™× ×œ×ª×§×¦×™×‘ ×•×œ×¦×¨×›×™× ×©×œ ×”××©×ª××©
    """
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": text}],
        temperature=0.4,
    )
    return response.choices[0].message.content

# =============================
# ×©××™×¨×ª ×œ×•×’
# =============================
def save_log(answers, models_data, summary, filename="car_advisor_logs.csv"):
    record = {
        "timestamp": datetime.datetime.now().isoformat(),
        "answers": json.dumps(answers, ensure_ascii=False),
        "summary": summary,
        "models_data": json.dumps(models_data, ensure_ascii=False)
    }
    if os.path.exists(filename):
        existing = pd.read_csv(filename)
        new_df = pd.DataFrame([record])
        final = pd.concat([existing, new_df], ignore_index=True)
    else:
        final = pd.DataFrame([record])
    final.to_csv(filename, index=False, encoding="utf-8-sig")

# =============================
# Streamlit UI
# =============================
st.set_page_config(page_title="Car-Advisor", page_icon="ğŸš—")
st.title("ğŸš— Car-Advisor â€“ ×™×•×¢×¥ ×¨×›×‘×™× ×—×›×")

COLUMN_TRANSLATIONS = {
    "price_range": "×˜×•×•×— ××—×™×¨×•×Ÿ",
    "availability": "×–××™× ×•×ª ×‘×™×©×¨××œ",
    "insurance_total": "×‘×™×˜×•×— ×—×•×‘×”+×¦×“ ×’' (×“×™×¡×§×œ×™×™××¨)",
    "license_fee": "××’×¨×ª ×¨×™×©×•×™",
    "maintenance": "×ª×—×–×•×§×” ×©× ×ª×™×ª",
    "common_issues": "×ª×§×œ×•×ª × ×¤×•×¦×•×ª",
    "fuel_consumption": "×¦×¨×™×›×ª ×“×œ×§",
    "depreciation": "×™×¨×™×“×ª ×¢×¨×š",
    "safety": "×‘×˜×™×—×•×ª",
    "parts_availability": "×—×œ×¤×™× ×‘×™×©×¨××œ"
}

# ×˜×¢×Ÿ ×××’×¨ ××©×¨×“ ×”×ª×—×‘×•×¨×”
df_cars = pd.read_csv("car_models_israel.csv")

# Session state
if "results_df" not in st.session_state:
    st.session_state["results_df"] = None
if "summary_text" not in st.session_state:
    st.session_state["summary_text"] = None

with st.form("car_form"):
    answers = {}
    answers["budget_min"] = int(st.text_input("×ª×§×¦×™×‘ ××™× ×™××œ×™ (â‚ª)", "20000"))
    answers["budget_max"] = int(st.text_input("×ª×§×¦×™×‘ ××§×¡×™××œ×™ (â‚ª)", "50000"))
    answers["engine"] = st.radio("×× ×•×¢ ××•×¢×“×£:", ["×œ× ××©× ×”", "×‘× ×–×™×Ÿ", "×“×™×–×œ", "×”×™×‘×¨×™×“×™", "×—×©××œ×™"])
    answers["engine_size"] = st.selectbox("× ×¤×— ×× ×•×¢ (×¡××´×§):", ["×œ× ××©× ×”", "1200", "1600", "2000", "3000+"])
    answers["year_range"] = st.selectbox("×©× ×•×ª ×™×™×¦×•×¨:", ["2010â€“2015", "2016â€“2020", "2021+"])
    answers["car_type"] = st.selectbox("×¡×•×’ ×¨×›×‘:", ["×¡×“××Ÿ", "×”××¦'×‘×§", "SUV", "×˜× ×“×¨", "××©×¤×—×ª×™"])
    answers["gearbox"] = st.radio("×’×™×¨:", ["×œ× ××©× ×”", "××•×˜×•××˜", "×™×“× ×™"])
    answers["usage"] = st.radio("×©×™××•×© ×¢×™×§×¨×™:", ["×¢×™×¨×•× ×™", "×‘×™×Ÿ-×¢×™×¨×•× ×™", "××¢×•×¨×‘"])
    answers["size"] = st.selectbox("×’×•×“×œ ×¨×›×‘:", ["×§×˜×Ÿ", "××©×¤×—×ª×™", "SUV", "×˜× ×“×¨"])
    answers["driver_age"] = st.selectbox("×’×™×œ ×”× ×”×’ ×”×¨××©×™:", ["18â€“20", "21â€“24", "25â€“30", "31â€“40", "40+"])
    answers["license_years"] = st.selectbox("×•×ª×§ ×¨×™×©×™×•×Ÿ × ×”×™×’×”:", ["×¤×—×•×ª ××©× ×”", "1â€“3", "4â€“7", "8+"])
    answers["insurance_history"] = st.selectbox("×¢×‘×¨ ×‘×™×˜×•×—×™/×ª×¢×‘×•×¨×ª×™:", ["×œ×œ× ×ª×‘×™×¢×•×ª/×ª××•× ×•×ª/×“×•×—×•×ª", "×ª×‘×™×¢×” ××—×ª", "×¨×™×‘×•×™ ×ª×‘×™×¢×•×ª"])
    answers["annual_km"] = st.selectbox("× ×¡×•×¢×” ×©× ×ª×™×ª (×§×´×):", ["×¤×—×•×ª ×-10,000", "10,000â€“20,000", "20,000â€“30,000", "30,000+"])
    answers["passengers"] = st.selectbox("××¡×¤×¨ × ×•×¡×¢×™× ×¢×™×§×¨×™:", ["×œ×¨×•×‘ ×œ×‘×“", "2â€“3", "××©×¤×—×” ××œ××”"])
    answers["maintenance_budget"] = st.selectbox("×™×›×•×œ×ª ×”×©×§×¢×” ×‘×ª×—×–×•×§×” ×©× ×ª×™×ª:", ["×¤×—×•×ª ×-3,000 â‚ª", "3,000â€“5,000 â‚ª", "××¢×œ 5,000 â‚ª"])
    answers["reliability_vs_comfort"] = st.radio("××” ×—×©×•×‘ ×™×•×ª×¨?", ["×××™× ×•×ª ×•×—×™×¡×›×•×Ÿ", "× ×•×—×•×ª/×‘×™×¦×•×¢×™× ×’× ×‘××—×™×¨ ×ª×—×–×•×§×”"])
    answers["eco"] = st.radio("×©×™×§×•×œ×™ ××™×›×•×ª ×¡×‘×™×‘×”:", ["×œ× ××©× ×”", "×—×©×•×‘ ×××•×“"])
    answers["resale_value"] = st.radio("×©××™×¨×ª ×¢×¨×š ×¢×ª×™×“×™×ª:", ["×—×©×•×‘", "×¤×—×•×ª ×—×©×•×‘"])
    answers["extra"] = st.text_area("××©×”×• × ×•×¡×£?")

    submitted = st.form_submit_button("×©×œ×— ×•×§×‘×œ ×”××œ×¦×”")

if submitted:
    with st.spinner("ğŸŒ Gemini ××—×¤×© ×“×’××™× ××ª××™××™×..."):
        candidate_models = fetch_candidate_models(answers)
    st.markdown("### ğŸ“ ×“×’××™× ×©-Gemini ×”×¦×™×¢")
    st.write(candidate_models)

    with st.spinner("ğŸ§¹ ×¡×™× ×•×Ÿ ××•×œ ××©×¨×“ ×”×ª×—×‘×•×¨×”..."):
        valid_models = filter_models_by_registry(candidate_models, answers, df_cars)
    st.markdown("### âœ… ×“×’××™× ××—×¨×™ ×¡×™× ×•×Ÿ ××©×¨×“ ×”×ª×—×‘×•×¨×”")
    st.write(valid_models)

    with st.spinner("ğŸ“Š Gemini ××—×–×™×¨ × ×ª×•× ×™× ×™×‘×©×™×..."):
        models_data = fetch_models_data_with_gemini(valid_models, answers)

    try:
        df = pd.DataFrame(models_data).T
        df.rename(columns=COLUMN_TRANSLATIONS, inplace=True)
        st.session_state["results_df"] = df
    except Exception as e:
        st.warning("âš ï¸ ×‘×¢×™×” ×‘× ×ª×•× ×™ JSON")
        st.write(models_data)

    with st.spinner("âš¡ GPT ××¡×›× ×•××“×¨×’..."):
        summary = final_recommendation_with_gpt(answers, models_data)
        st.session_state["summary_text"] = summary

    save_log(answers, models_data, summary)

# ×”×¦×’×ª ×ª×•×¦××•×ª ××”-Session State
if st.session_state["results_df"] is not None:
    st.subheader("ğŸ“Š ×”×©×•×•××ª × ×ª×•× ×™× ×‘×™×Ÿ ×”×“×’××™×")
    st.dataframe(st.session_state["results_df"], use_container_width=True)
    csv = st.session_state["results_df"].to_csv(index=True, encoding="utf-8-sig")
    st.download_button("â¬‡ï¸ ×”×•×¨×“ ×›-CSV", csv, "car_advisor.csv", "text/csv")

if st.session_state["summary_text"] is not None:
    st.subheader("ğŸ” ×”×”××œ×¦×” ×”×¡×•×¤×™×ª ×©×œ×š")
    st.write(st.session_state["summary_text"])

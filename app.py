import os
import re
import json
import requests
import datetime
import streamlit as st
import pandas as pd
from openai import OpenAI

# =============================
# ××¤×ª×—×•×ª API
# =============================
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")

if not OPENAI_API_KEY or not GEMINI_API_KEY:
    st.error("âŒ ×œ× × ××¦××• ××¤×ª×—×•×ª API. ×•×“× ×©×”×’×“×¨×ª ××•×ª× ×‘-secrets.")
    st.stop()

client = OpenAI(api_key=OPENAI_API_KEY)

# =============================
# ×§×¨×™××” ×‘×˜×•×—×” ×œ-Gemini
# =============================
def safe_gemini_call(payload, model="gemini-2.0-flash"):
    url = f"https://generativelanguage.googleapis.com/v1/models/{model}:generateContent"
    headers = {"Content-Type": "application/json"}
    params = {"key": GEMINI_API_KEY}
    try:
        r = requests.post(url, headers=headers, params=params, json=payload, timeout=120)
        data = r.json()
        if "candidates" not in data:
            return f"×©×’×™××ª Gemini: {data}"
        return data["candidates"][0]["content"]["parts"][0]["text"]
    except Exception as e:
        return f"×©×’×™××”: {e}"

# =============================
# ×¤×™×¢× ×•×— JSON
# =============================
def parse_gemini_json(answer):
    cleaned = answer.strip()
    if "```" in cleaned:
        match = re.search(r"```(?:json)?(.*?)```", cleaned, re.DOTALL)
        if match:
            cleaned = match.group(1).strip()
    try:
        return json.loads(cleaned)
    except Exception:
        return {}

# =============================
# ×©×œ×‘ 1 â€“ ×¡×™× ×•×Ÿ ×¨××©×•× ×™ ××•×œ ×××’×¨ ××©×¨×“ ×”×ª×—×‘×•×¨×”
# =============================
def filter_with_mot(answers, mot_file="car_models_israel_clean.csv"):
    if not os.path.exists(mot_file):
        st.error(f"âŒ ×§×•×‘×¥ ×”×××’×¨ '{mot_file}' ×œ× × ××¦× ×‘×ª×™×§×™×™×”. ×•×“× ×©×”×¢×œ×™×ª ××•×ª×•.")
        return []

    df = pd.read_csv(mot_file)

    # ×”××¨×•×ª ×‘×˜×•×—×•×ª
    for col in ["year", "engine_cc"]:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors="coerce")

    year_min = int(answers["year_min"])
    year_max = int(answers["year_max"])
    cc_min = int(answers["engine_cc_min"])
    cc_max = int(answers["engine_cc_max"])

    mask_year = df["year"].between(year_min, year_max, inclusive="both")
    mask_cc = df["engine_cc"].between(cc_min, cc_max, inclusive="both")

    # ×¡×™× ×•×Ÿ ×œ×¤×™ ×¡×•×’ ×“×œ×§
    mask_fuel = df["fuel_normalized"] == answers["engine"]

    # ×¡×™× ×•×Ÿ ×œ×¤×™ ×’×™×¨
    if answers["gearbox"] == "××•×˜×•××˜":
        mask_gear = df["automatic"].astype(int) == 1
    elif answers["gearbox"] == "×™×“× ×™":
        mask_gear = df["automatic"].astype(int) == 0
    else:
        mask_gear = pd.Series([True] * len(df), index=df.index)

    df_filtered = df[mask_year & mask_cc & mask_fuel & mask_gear].copy()

    return df_filtered.to_dict(orient="records")

# =============================
# ×©×œ×‘ 2 â€“ Gemini ××•×¡×™×£ × ×ª×•× ×™× ×™×‘×©×™×
# =============================
def fetch_models_from_gemini(answers, verified_models):
    payload = {
        "contents": [{
            "role": "user",
            "parts": [{
                "text": f"""
                ×”××©×ª××© × ×ª×Ÿ ××ª ×”×”×¢×“×¤×•×ª ×”×‘××•×ª:
                {answers}

                ×”× ×” ×¨×©×™××ª ×¨×›×‘×™× ×©×¢×‘×¨×• ×¡×™× ×•×Ÿ ×¨××©×•× ×™:
                {verified_models}

                ×¢×‘×•×¨ ×›×œ ×¨×›×‘ ×”×—×–×¨ ××š ×•×¨×§ JSON ×¢× ×”×©×“×•×ª ×”×‘××™×, × ×ª×•× ×™× ×œ×™×©×¨××œ ×‘×œ×‘×“:
                {{
                  "Model (year, engine, fuel)": {{
                     "price_range": "×˜×•×•×— ××—×™×¨×•×Ÿ ×××•×¦×¢ ×‘×™×“ ×©× ×™×™×” (â‚ª)",
                     "insurance_total": "×¢×œ×•×ª ×‘×™×˜×•×— ×—×•×‘×” + ×¦×“ ×’' (â‚ª)",
                     "maintenance": "×ª×—×–×•×§×” ×©× ×ª×™×ª ×××•×¦×¢×ª (â‚ª)",
                     "common_issues": "×ª×§×œ×•×ª × ×¤×•×¦×•×ª",
                     "depreciation": "×™×¨×™×“×ª ×¢×¨×š ×××•×¦×¢×ª (%)",
                     "safety": "×“×™×¨×•×’ ×‘×˜×™×—×•×ª (×›×•×›×‘×™×)",
                     "parts_availability": "×–××™× ×•×ª ×—×œ×¤×™× ×‘×™×©×¨××œ",
                     "turbo": 0/1
                  }}
                }}

                âŒ ××œ ×ª×•×¡×™×£ ×“×’××™× ×—×“×©×™×.
                âŒ ××œ ×ª×¡× ×Ÿ ×œ×¤×™ ×©××œ×•×Ÿ.
                âœ… ×”×—×–×¨ ××š ×•×¨×§ × ×ª×•× ×™× ×™×‘×©×™× ××”××§×•×¨×•×ª.
                """
            }]
        }]
    }
    answer = safe_gemini_call(payload)
    return parse_gemini_json(answer)

# =============================
# ×©×œ×‘ 3 â€“ GPT ××¡× ×Ÿ ×•××“×¨×’
# =============================
def final_recommendation_with_gpt(answers, enriched_data):
    text = f"""
    ×ª×©×•×‘×•×ª ×”××©×ª××©:
    {answers}

    × ×ª×•× ×™ ×”×“×’××™× (××’×™×× ×™×™):
    {enriched_data}

    ×¦×•×¨ ×¡×™×›×•× ×‘×¢×‘×¨×™×ª:
    - ×‘×—×¨ ×¢×“ 5 ×“×’××™× ×‘×œ×‘×“
    - ×¡× ×Ÿ ×œ×¤×™ ×ª×§×¦×™×‘ ××—×™×¨×•×Ÿ, ×ª×—×–×•×§×”, ×™×¨×™×“×ª ×¢×¨×š, ×©×™××•×© ×¢×™×§×¨×™, ×××™× ×•×ª/× ×•×—×•×ª, ×©××™×¨×ª ×¢×¨×š, ×‘×™×˜×•×—, ××™×›×•×ª ×¡×‘×™×‘×”
    - ×¤×¨×˜ ×™×ª×¨×•× ×•×ª ×•×—×¡×¨×•× ×•×ª
    - ×¦×•×¨ ×˜×‘×œ×ª 10 ×¤×¨××˜×¨×™× ×¡×•×¤×™×ª
    """
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": text}],
        temperature=0.4,
    )
    return response.choices[0].message.content

# =============================
# ×©×œ×‘ 4 â€“ Cache (×©××™×¨×” ×—×•×“×©×™×ª)
# =============================
def save_cache(enriched_data, filename="car_data_cache.csv"):
    df_new = pd.DataFrame.from_dict(enriched_data, orient="index")
    df_new["update_date"] = datetime.date.today().isoformat()

    if os.path.exists(filename):
        df_old = pd.read_csv(filename)
        final = pd.concat([df_old, df_new], ignore_index=True)
    else:
        final = df_new

    final.to_csv(filename, index=False, encoding="utf-8-sig")

# =============================
# Streamlit UI
# =============================
st.set_page_config(page_title="Car-Advisor", page_icon="ğŸš—")
st.title("ğŸš— Car-Advisor â€“ ×™×•×¢×¥ ×¨×›×‘×™× ×—×›×")

with st.form("car_form"):
    answers = {}
    answers["budget_min"] = int(st.text_input("×ª×§×¦×™×‘ ××™× ×™××œ×™ (â‚ª)", "5000"))
    answers["budget_max"] = int(st.text_input("×ª×§×¦×™×‘ ××§×¡×™××œ×™ (â‚ª)", "20000"))
    answers["engine"] = st.radio("×× ×•×¢ ××•×¢×“×£:", ["×‘× ×–×™×Ÿ", "×“×™×–×œ", "×”×™×‘×¨×™×“×™-×‘× ×–×™×Ÿ", "×”×™×‘×¨×™×“×™-×“×™×–×œ", "×—×©××œ"])
    answers["engine_cc_min"] = int(st.text_input("× ×¤×— ×× ×•×¢ ××™× ×™××œ×™ (×¡××´×§):", "1200"))
    answers["engine_cc_max"] = int(st.text_input("× ×¤×— ×× ×•×¢ ××§×¡×™××œ×™ (×¡××´×§):", "2000"))
    answers["year_min"] = st.text_input("×©× ×ª ×™×™×¦×•×¨ ××™× ×™××œ×™×ª:", "2000")
    answers["year_max"] = st.text_input("×©× ×ª ×™×™×¦×•×¨ ××§×¡×™××œ×™×ª:", "2020")
    answers["car_type"] = st.selectbox("×¡×•×’ ×¨×›×‘:", ["×¡×“××Ÿ", "×”××¦'×‘×§", "SUV", "××™× ×™", "×¡×•×¤×¨ ××™× ×™", "×¡×˜×™×™×©×Ÿ", "×˜× ×“×¨", "××©×¤×—×ª×™"])
    answers["gearbox"] = st.radio("×’×™×¨:", ["×œ× ××©× ×”", "××•×˜×•××˜", "×™×“× ×™"])
    answers["turbo"] = st.radio("×× ×•×¢ ×˜×•×¨×‘×•:", ["×œ× ××©× ×”", "×›×Ÿ", "×œ×"])
    answers["usage"] = st.radio("×©×™××•×© ×¢×™×§×¨×™:", ["×¢×™×¨×•× ×™", "×‘×™×Ÿ-×¢×™×¨×•× ×™", "××¢×•×¨×‘"])
    answers["driver_age"] = st.selectbox("×’×™×œ ×”× ×”×’ ×”×¨××©×™:", ["×¢×“ 21", "21â€“24", "25â€“34", "35+"])
    answers["license_years"] = st.selectbox("×•×ª×§ ×¨×™×©×™×•×Ÿ × ×”×™×’×”:", ["×¤×—×•×ª ××©× ×”", "1â€“3 ×©× ×™×", "3â€“5 ×©× ×™×", "××¢×œ 5 ×©× ×™×"])
    answers["insurance_history"] = st.selectbox("×¢×‘×¨ ×‘×™×˜×•×—×™/×ª×¢×‘×•×¨×ª×™:", ["×œ×œ×", "×ª××•× ×” ××—×ª", "××¡×¤×¨ ×ª×‘×™×¢×•×ª"])
    answers["annual_km"] = st.selectbox("× ×¡×•×¢×” ×©× ×ª×™×ª (×§×´×):", ["×¢×“ 10,000", "10,000â€“20,000", "20,000â€“30,000", "××¢×œ 30,000"])
    answers["passengers"] = st.selectbox("××¡×¤×¨ × ×•×¡×¢×™× ×¢×™×§×¨×™:", ["×œ×¨×•×‘ ×œ×‘×“", "2 ×× ×©×™×", "3â€“5 × ×•×¡×¢×™×", "××¢×œ 5"])
    answers["maintenance_budget"] = st.selectbox("×™×›×•×œ×ª ×ª×—×–×•×§×”:", ["××ª×—×ª 3,000 â‚ª", "3,000â€“5,000 â‚ª", "××¢×œ 5,000 â‚ª"])
    answers["reliability_vs_comfort"] = st.selectbox("××” ×—×©×•×‘ ×™×•×ª×¨?", ["×××™× ×•×ª ××¢×œ ×”×›×•×œ", "××™×–×•×Ÿ ×××™× ×•×ª ×•× ×•×—×•×ª", "× ×•×—×•×ª/×‘×™×¦×•×¢×™×"])
    answers["eco_pref"] = st.selectbox("×©×™×§×•×œ×™ ××™×›×•×ª ×¡×‘×™×‘×”:", ["×—×©×•×‘ ×¨×›×‘ ×™×¨×•×§/×—×¡×›×•× ×™", "×œ× ××©× ×”"])
    answers["resale_value"] = st.selectbox("×©××™×¨×ª ×¢×¨×š ×¢×ª×™×“×™×ª:", ["×—×©×•×‘ ×œ×©××•×¨ ×¢×œ ×¢×¨×š", "×¤×—×•×ª ×—×©×•×‘"])
    answers["extra"] = st.text_area("××©×”×• × ×•×¡×£ ×©×ª×¨×¦×” ×œ×¦×™×™×Ÿ?")
    submitted = st.form_submit_button("×©×œ×— ×•×§×‘×œ ×”××œ×¦×”")

if submitted:
    with st.spinner("ğŸ“Š ×¡×™× ×•×Ÿ ×§×©×™×— ××•×œ ×”×××’×¨..."):
        verified_models = filter_with_mot(answers)

    with st.spinner("ğŸŒ Gemini ××•×¡×™×£ × ×ª×•× ×™× ×™×‘×©×™×..."):
        enriched_data = fetch_models_from_gemini(answers, verified_models)

    with st.spinner("âš¡ GPT ××¡× ×Ÿ ×•××“×¨×’..."):
        summary = final_recommendation_with_gpt(answers, enriched_data)

    st.subheader("ğŸ” ×”×”××œ×¦×” ×”×¡×•×¤×™×ª ×©×œ×š")
    st.write(summary)

    # ×©××™×¨×” ×‘-Cache
    save_cache(enriched_data)
